{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Notebook.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"nO5dBqvy3KLM","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Install Required Packages.\n","\n","!apt update && apt install protobuf-compiler -y\n","!pip install lxml cython numpy pillow matplotlib\n","!pip install pycocotools tensorflow==1.15.0 kaggle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OUKEsVvH3KLe","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Required Imports\n","\n","%matplotlib inline\n","%tensorflow_version 1.x\n","%load_ext tensorboard\n","import os, sys, shutil, fnmatch, random, json\n","import xml.etree.ElementTree as ET\n","import numpy as np\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1FePF-f3KLk","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Some Useful Functions\n","\n","def download_file(url, save_as, continue_existing=True):\n","    if continue_existing:\n","        !wget -c \"{url}\" -O \"{save_as}\"\n","    else:\n","        !wget \"{url}\" -O \"{save_as}\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fs374VBE4Htz","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Mount Google Drive\n","\n","GDRIVE_WORKSPACE = 'Potholes-Detection'  #@param {type: 'string'}\n","\n","MOUNT_PATH = '/gdrive'\n","WORKSPACE_PATH = os.path.join(MOUNT_PATH, 'My Drive', GDRIVE_WORKSPACE)\n","\n","if not os.path.exists(MOUNT_PATH):\n","  from google.colab import drive\n","  drive.mount(MOUNT_PATH)\n","  !mkdir -p \"{WORKSPACE_PATH}\"\n","  !ln -s \"{WORKSPACE_PATH}\" \"root\"\n","  os.chdir(\"root\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mog1SdwF3KLp","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Create Directory Tree\n","\n","new_folders = \" \".join(['annotations', 'archives', 'evaluations', 'exported-models', 'pre-trained-models', 'trainings'])\n","!mkdir -p {new_folders}\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OdXseA3yUVwE","colab_type":"text"},"source":["### Important!! Before Executing Next\n","\n","You need a **Kaggle API Key** to download the dataset here.\n","\n","To use the Kaggle API, sign up for a Kaggle account at https://www.kaggle.com. Then go to the **My Account** of your user profile (https://www.kaggle.com/YOUR_USERNAME/account) and select **Create API Token**. This will trigger the download of **kaggle.json**, a file containing your API credentials.\n","\n","Now replace according to your **kaggle.json** file :\n","- **YOUR_USERNAME** with your username\n","- **YOUR_API_KEY** with your key"]},{"cell_type":"code","metadata":{"id":"bGa0Ov-NOmVZ","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Set Environment Variables and Paths\n","\n","KAGGLE_USERNAME = 'YOUR_USERNAME' #@param {type: 'string'}\n","KAGGLE_API_KEY = 'YOUR_API_KEY' #@param {type: 'string'}\n","\n","os.environ['KAGGLE_USERNAME'] = KAGGLE_USERNAME\n","os.environ['KAGGLE_KEY'] = KAGGLE_API_KEY\n","\n","new_paths = [os.path.join(os.getcwd(), f'models/research/{d}') for d in ['', 'object_detection', 'slim']]\n","\n","for p in new_paths:\n","    if p not in sys.path:\n","        sys.path.append(p)\n","os.environ['PYTHONPATH'] = ':'.join(new_paths)\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wIiD1ww33KLv","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Download Tensorflow Models Repository\n","\n","if not os.path.exists('models'):\n","    download_file('https://github.com/tensorflow/models/archive/master.zip', 'archives/models.zip', continue_existing=False)\n","    !unzip -qnd archives \"archives/models.zip\" && mv archives/models-* models\n","\n","!cd models/research && protoc object_detection/protos/*.proto --python_out=."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eyvDsJt_3KL1","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Split Dataset into Train and Test.\n","\n","DATASET_PATH = '/dataset' #@param {type:'string'}\n","TEST_RATIO = 0.2 #@param {type:\"slider\", min:0.01, max:0.99, step:0.01}\n","FORCE_RESPLIT = False #@param {type:\"boolean\"}\n","\n","IMAGES_PATH = os.path.join(DATASET_PATH, 'annotated-images')\n","\n","if not os.path.exists(DATASET_PATH):\n","    !kaggle datasets download -p archives chitholian/annotated-potholes-dataset\n","    !unzip -qd \"{DATASET_PATH}\" \"archives/annotated-potholes-dataset.zip\"\n","\n","if FORCE_RESPLIT or not os.path.exists(os.path.join(DATASET_PATH, 'splits.json')):\n","    all_xmls = fnmatch.filter(os.listdir(IMAGES_PATH), '*.xml')\n","    total_size = len(all_xmls)\n","    max_test_ratio = (total_size - 1)/total_size  # Training set must have at least 1 member.\n","    assert 0 <= TEST_RATIO <= max_test_ratio, f'TEST_RATIO must be in range [0, {max_test_ratio}]'\n","    test_set = set()\n","    train_set = set()\n","    while len(test_set) < round(total_size * TEST_RATIO):\n","        test_set.add(all_xmls[random.randint(0, total_size - 1)])\n","    for xml in all_xmls:\n","        if xml not in test_set:\n","            train_set.add(xml)\n","    with open(os.path.join(DATASET_PATH, 'splits.json'), 'w') as f:\n","        json.dump({'train': list(train_set), 'test': list(test_set)}, f)\n","        print(f'Splits written to \"{f.name}\"')\n","else:\n","    with open(os.path.join(DATASET_PATH, 'splits.json'), 'r') as f:\n","        splits = json.load(f)\n","        train_set = splits['train']\n","        test_set = splits['test']\n","\n","# print('-----Training Set', train_set)\n","# print('-----Test Set', test_set)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RL6a_fyl3KL6","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Create LabelMap and TFRECORD Files\n","\n","LABELS = ['pothole']  #@param {type:\"raw\"}\n","FORCE_RECREATE = False  #@param {type:\"boolean\"}\n","\n","with open('annotations/labels.pbtxt', 'w') as f:\n","    for i in range(len(LABELS)):\n","        f.write(f'''\\\n","item {{\n","    id: {i + 1}\n","    name: \"{LABELS[i]}\"\n","}}\n","''')\n","\n","def class_text_to_int(class_name):\n","    try:\n","        return LABELS.index(class_name) + 1\n","    except:\n","        return None\n","\n","def create_tfrecord(xml_files, output_file):\n","    writer = tf.python_io.TFRecordWriter(output_file)\n","\n","    for xml_file in xml_files:\n","        tree = ET.parse(os.path.join(IMAGES_PATH, xml_file))\n","        root = tree.getroot()\n","\n","        width = int(root.find('size/width').text)\n","        height = int(root.find('size/height').text)\n","        filename = root.find('filename').text.encode('utf8')\n","        image_format = root.find('filename').text.split('.')[-1].encode('utf8')\n","\n","        with tf.gfile.GFile(os.path.join(IMAGES_PATH, root.find('filename').text), 'rb') as fid:\n","            encoded_img = fid.read()\n","\n","        class_names = []\n","        class_ids = []\n","        xmins = []\n","        ymins = []\n","        xmaxs= []\n","        ymaxs = []\n","        truncated = []\n","        difficulties = []\n","\n","        for m in root.iter('object'):\n","            class_names.append(m.find('name').text.encode('utf8'))\n","            class_ids.append(int(class_text_to_int(m.find('name').text)))\n","            xmins.append(int(m.find('bndbox/xmin').text) / width)\n","            ymins.append(int(m.find('bndbox/ymin').text) / height)\n","            xmaxs.append(int(m.find('bndbox/xmax').text) / width)\n","            ymaxs.append(int(m.find('bndbox/ymax').text) / height)\n","            truncated.append(int(m.find('truncated').text))\n","            difficulties.append(int(m.find('difficult').text))\n","\n","        tf_example = tf.train.Example(features=tf.train.Features(feature={\n","            'image/height': tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n","            'image/width': tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n","            'image/filename': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename])),\n","            'image/source_id': tf.train.Feature(bytes_list=tf.train.BytesList(value=[filename])),\n","            'image/encoded': tf.train.Feature(bytes_list=tf.train.BytesList(value=[encoded_img])),\n","            'image/format': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_format])),\n","            'image/object/bbox/xmin': tf.train.Feature(float_list=tf.train.FloatList(value=xmins)),\n","            'image/object/bbox/xmax': tf.train.Feature(float_list=tf.train.FloatList(value=xmaxs)),\n","            'image/object/bbox/ymin': tf.train.Feature(float_list=tf.train.FloatList(value=ymins)),\n","            'image/object/bbox/ymax': tf.train.Feature(float_list=tf.train.FloatList(value=ymaxs)),\n","            'image/object/class/text': tf.train.Feature(bytes_list=tf.train.BytesList(value=class_names)),\n","            'image/object/class/label': tf.train.Feature(int64_list=tf.train.Int64List(value=class_ids)),\n","            'image/object/truncated': tf.train.Feature(int64_list=tf.train.Int64List(value=truncated)),\n","            'image/object/difficult': tf.train.Feature(int64_list=tf.train.Int64List(value=difficulties))\n","        }))\n","\n","        writer.write(tf_example.SerializeToString())\n","\n","    writer.close()\n","    print('Created tfrecord file:', output_file)\n","\n","if FORCE_RECREATE or not os.path.exists('annotations/training.record'):\n","    create_tfrecord(train_set, 'annotations/training.record')\n","if FORCE_RECREATE or not os.path.exists('annotations/evaluation.record'):\n","    create_tfrecord(test_set, 'annotations/evaluation.record')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPRrQslr3KL_","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Prepare a Pre-Trained Model\n","\n","MODEL_NAME = 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03'  #@param {type:\"string\"}\n","TUNE_CONFIG = True  #@param {type:\"boolean\"}\n","\n","INITIAL_LR = 0.005  #@param {type:\"number\"}\n","DECAY_STEPS = 6000  #@param {type:\"integer\"}\n","DECAY_FACTOR = 0.50  #@param {type:\"number\"}\n","BATCH_SIZE =     24  #@param {type:\"integer\"}\n","QUANTIZATION_DELAY = 30000  #@param {type:\"integer\"}\n","\n","REMOVE_BATCH_NORM_TRAINABLE = True  #@param {type:\"boolean\"}\n","\n","if not os.path.exists(f'pre-trained-models/{MODEL_NAME}'):\n","    download_file(f'http://download.tensorflow.org/models/object_detection/{MODEL_NAME}.tar.gz', f'archives/{MODEL_NAME}.tar.gz')\n","    !tar -xz -C \"pre-trained-models\" -f \"archives/{MODEL_NAME}.tar.gz\"\n","\n","if not os.path.exists(f'trainings/{MODEL_NAME}/pipeline-mod.config'):\n","    !mkdir -p \"trainings/{MODEL_NAME}\"\n","    !cp \"pre-trained-models/{MODEL_NAME}/pipeline.config\" \"trainings/{MODEL_NAME}/pipeline-mod.config\"\n","\n","## Tune Configurations\n","if TUNE_CONFIG:\n","    !sed -i \"trainings/{MODEL_NAME}/pipeline-mod.config\" \\\n","        -e 's/fine_tune_checkpoint:.*/fine_tune_checkpoint: \"pre-trained-models\\/{MODEL_NAME}\\/model.ckpt\"/g' \\\n","        -e 's/label_map_path:.*/label_map_path: \"annotations\\/labels.pbtxt\"/g' \\\n","        -e 's/input_path:.*train.*/input_path: \"annotations\\/training.record\"/g' \\\n","        -e 's/input_path:.*val.*/input_path: \"annotations\\/evaluation.record\"/g' \\\n","        -e 's/num_classes:.*/num_classes: {len(LABELS)}/g' \\\n","        -e 's/num_examples:.*/num_examples: {len(test_set)}/g' \\\n","        -e 's/fixed_shape_resizer/keep_aspect_ratio_resizer/g' \\\n","        -e 's/width:/pad_to_max_dimension: true\\n        max_dimension:/g' \\\n","        -e 's/height:/min_dimension:/g' \\\n","        -e 's/shuffle:.*/shuffle: true/g' \\\n","        -e 's/include_metrics_per_category:.*/include_metrics_per_category: false/g' \\\n","        -e 's/delay:.*/delay: {QUANTIZATION_DELAY}/g'\n","\n","    if INITIAL_LR > 0:\n","        !sed 's/initial_learning_rate:.*/initial_learning_rate: {INITIAL_LR}/g' -i \"trainings/{MODEL_NAME}/pipeline-mod.config\"\n","    if DECAY_STEPS >= 0:\n","        !sed 's/decay_steps:.*/decay_steps: {DECAY_STEPS}/g' -i \"trainings/{MODEL_NAME}/pipeline-mod.config\"\n","    if DECAY_FACTOR > 0:\n","        !sed 's/decay_factor:.*/decay_factor: {DECAY_FACTOR}/g' -i \"trainings/{MODEL_NAME}/pipeline-mod.config\"\n","    if REMOVE_BATCH_NORM_TRAINABLE:\n","        !sed 's/batch_norm_trainable:.*//g' -i \"trainings/{MODEL_NAME}/pipeline-mod.config\"\n","    if BATCH_SIZE > 0:\n","        !sed 's/batch_size:.*/batch_size: {BATCH_SIZE}/g' -i \"trainings/{MODEL_NAME}/pipeline-mod.config\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mlHZhFwA3KMF","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Launch TensorBoard\n","\n","%tensorboard --logdir \"trainings/{MODEL_NAME}\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"stZwY2r43KMK","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Start Training\n","\n","!python models/research/object_detection/model_main.py \\\n","    --model_dir \"trainings/{MODEL_NAME}\" \\\n","    --pipeline_config_path \"trainings/{MODEL_NAME}/pipeline-mod.config\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7M_PvAQu6wfo","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Export Inference Graph\n","\n","EXPORT_PATH = f\"exported-models/{MODEL_NAME}\"\n","\n","###########!!! Important !!!###########\n","## Note: Change the checkpoint value according to your needs.\n","##       Find them in \"trainings/{MODEL_NAME}/model.ckpt-{CHECKPOINT}\"\n","CHECKPOINT = 104384  #@param {type:\"integer\"}\n","\n","!python models/research/object_detection/export_tflite_ssd_graph.py \\\n","    --pipeline_config_path \"trainings/{MODEL_NAME}/pipeline-mod.config\" \\\n","    --trained_checkpoint_prefix \"trainings/{MODEL_NAME}/model.ckpt-{CHECKPOINT}\" \\\n","    --output_directory \"{EXPORT_PATH}\" \\\n","    --config_override \" \\\n","    model {{ \\\n","      ssd {{ \\\n","          image_resizer {{ \\\n","              fixed_shape_resizer {{ \\\n","                  width: 300 \\\n","                  height: 300 \\\n","              }} \\\n","          }} \\\n","      }} \\\n","    }}\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKnEx3_999Oy","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Create .tflite From .pb\n","\n","!tflite_convert --output_file \"{EXPORT_PATH}/model.tflite\" \\\n","  --graph_def_file \"{EXPORT_PATH}/tflite_graph.pb\" \\\n","  --input_arrays \"normalized_input_image_tensor\" \\\n","  --output_arrays 'TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n","  --input_shape \"1,300,300,3\" \\\n","  --allow_custom_ops \\\n","  --inference_type QUANTIZED_UINT8 \\\n","  --std_dev_values 128 \\\n","  --mean_values 128"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4qXahjtFDfW","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Run Evaluation (Optional)\n","\n","!python models/research/object_detection/model_main.py \\\n","    --model_dir \"evaluations/{MODEL_NAME}\" \\\n","    --eval_only \\\n","    --run_once \\\n","    --checkpoint_dir \"trainings/{MODEL_NAME}\" \\\n","    --pipeline_config_path \"trainings/{MODEL_NAME}/pipeline-mod.config\"\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1KIFR7ItjPNf","colab_type":"code","cellView":"both","colab":{}},"source":["#@title Run Test on Images\n","\n","from PIL import Image, ImageDraw\n","import random\n","\n","NUM_TEST_IMAGES =   10 #@param {type: 'integer'}\n","CHOOSE_RANDOMLY = True  #@param {type: 'boolean'}\n","MIN_DETECTION_SCORE =  0.5 #@param {type:\"slider\", min:0.01, max:0.999, step: 0.01}\n","SHOW_FULL_SIZE = False  #@param {type: 'boolean'}\n","\n","if not CHOOSE_RANDOMLY:\n","  random.seed(0)  # Setting a fixed seed makes the random function like a fixed requence.\n","\n","ALL_IMAGES = fnmatch.filter(os.listdir(IMAGES_PATH), '*.jpg')\n","TEST_IMAGES = [os.path.join(IMAGES_PATH, random.choice(ALL_IMAGES)) for i in range(NUM_TEST_IMAGES)]\n","\n","# Load TFLite model and allocate tensors.\n","interpreter = tf.lite.Interpreter(model_path=f\"{EXPORT_PATH}/model.tflite\")\n","interpreter.allocate_tensors()\n","\n","# Get input and output tensors.\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","input_shape = input_details[0]['shape']\n","\n","for i in TEST_IMAGES:\n","  img_orig = Image.open(i)\n","  img2 = img_orig.resize((300, 300))\n","  \n","  if SHOW_FULL_SIZE:\n","    image = img_orig\n","  else:\n","    image = img2\n","  \n","  w, h = image.size\n","  draw = ImageDraw.Draw(image)\n","\n","  img = np.asarray(img2, dtype=np.uint8)\n","\n","  input_data = np.reshape(img, input_shape)\n","  interpreter.set_tensor(input_details[0]['index'], input_data)\n","\n","  interpreter.invoke()\n","\n","  detections = interpreter.get_tensor(output_details[3]['index'])\n","  locations = interpreter.get_tensor(output_details[0]['index'])\n","  scores = interpreter.get_tensor(output_details[2]['index'])\n","  \n","  for d in range(int(detections[0])):\n","    loc = locations[0][d]\n","    score = scores[0][d]\n","    if score >= MIN_DETECTION_SCORE:\n","      loc = [loc[3] * w, loc[2] * h, loc[1] * w, loc[0] * h]\n","\n","      draw.rectangle(loc)\n","      draw.text((loc[2:4]), '{:.2f}%'.format(score * 100))\n","  display(image)"],"execution_count":0,"outputs":[]}]}